---
title: <span style="color:#034a94"> **Introducción a Probabilidad**</span>
author: "Nivelatorio de Estadística"
output:
  html_document:
    code_folding: hide
    css: style.css
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```

<br/><br/>

```{r, message=FALSE, warning=FALSE, fig.align='center'}
library("tm")
library("SnowballC")
library("wordcloud2")
library("RColorBrewer")
# nube1 <- read.csv("data/nube1.csv")

palabras=c("Probabilidad", "azar", 
           "aleatorio"   , "deterministico", 
           "incertidumbre",  "probable", 
           "imposible",  "cierto", 
           "incierto", "enfoque clásico", 
           "enfoque subjetivo", "enfoque frecuentisto", 
           "evento",    "experimento", 
           "conjunto",  "unión", 
           "interseción", "conjunto",
           "marginal", "Pascal",
           "Fermat", "De Meré",
           "Gauss",   "Laplace",
           "Kolmogorov", "probabilidad marginal",
           "probabilidad conjunta", "probabilidad condicional",
           "Bayes", "Teorema de Bayes",
           "Riesgo", "Indicador", "Decisión", "[0,1]")  #30

replicas=c(20, 8, 8, 8, 8, 8, 8, 8, 8, 4, 
           4,  4, 4, 4, 4, 4, 4, 4, 4, 6, 
           6, 6,  5, 5, 5, 4, 5, 6, 5,7,
           5,6,7,4)

nube1=rep(palabras, replicas)

t=data.frame(table(nube1))

dword=t[,1]
dfreq=t[,2]
set.seed(1234)
# wordcloud(words = dword, freq = dfreq, min.freq = 1,
#            max.words=200, random.order=FALSE, rot.per=0.35, 
#            colors=brewer.pal(8, "Dark2"))

# c("#F27F0C", "#F7AD19", "#053F5C", "#429EBD", "#034A94")
library(wordcloud2)
wordcloud2(data = t, 
           size = 0.5, 
           color=rep_len( c("#F27F0C", "#F7AD19", "#053F5C", "#429EBD", "#034A94"), 
           nrow(demoFreq)),
           rotateRatio = 0)
```


La probabilidad es un concepto desarrollado en el siglo XVII, a partir de la contribución de los matemáticos Blaise Pascal y Pierre de Fermat. Esta contribución fué originada a traves de correspondencia en la que se plantean las soluciones al problema planteado por un noble sobre la  interrupción de un juego de dados antes de que se alcanzara la puntuación necesaria para ganar (posiblemente debido a la prioridad de atender asustos relacionados con la guerra), y la pregunta era cómo dividir equitativamente el premio entre los jugadores en función de la situación actual del juego. 

<br/>

Pascal y Fermat desarrollaron los fundamentos de la teoría de la probabilidad al abordar este problema, de esta manera introducen los conceptos básicos de la probabilidad bajo en enfoque clásico

<br/>

Además de ellos tambien se conocen trabajos como el de Jacob Bernoulli realizó contribuciones en el campo de la astronomía y otras aplicaciones que se plasman en el libro "Ars Conjectandi" en 1713. En este libro, Jacob Bernoulli introdujo la ley de los grandes números, que establece que a medida que aumenta el número de repeticiones de un experimento aleatorio, la frecuencia relativa de un evento tiende a acercarse a su probabilidad teórica.

<br/>

Hoy dia este concepto esta implicito en todos los campos como la teoría Bayesiana basada en el teorema de Bayes, Metodo de Montecarlos empleados en la simulación de eventos complejos, aportes al desarrollo de la ineligendia artificial principalmente en lo que respecta al aprendizaje auomatico y el reconocimiento de patrones, la big data y el aprendizaje automatico y la probabilidad cuanticaen el ambito de la fisica moderna.

<br/>

Hablar de probabilidad reúne una serie de conceptos, algunos de ellos se presentan en la nube de palabras. A continuación se definen los más importantes :

<br/><br/><br/>

## <span style="color:#034a94">**Experimento aleatorio**</span>

<br/>

<div class="content-box-blue">
Acción que puede ser replicada bajo las mismas condiciones y cuyo resultado no se conoce por anticipado.
</div>

+ $E_{1}$: Lanzar una moneda dos veces y observar los resultados obtenidos en sus caras superiores 

+ $E_{2}$: Lanzar dos dados y observar la suma de los resultados superiores 

+ $E_{3}$: Realizar un examen de estadística y observar el resultado obtenido  

+ $E_{4}$: En una salida de campo, observo si se cumple o no, totalmente el objetivo planteado 

+ $E_{5}$: Observo el número total de ensayos de laboratorio exitosos en  20 intentos realizados.


<br/><br/><br/>

## <span style="color:#034a94">**Espacio muestral**</span> 

<br/>

<div class="content-box-blue">
Conjunto de todos los posibles valores que puede tomar el experimento aleatorio. Este conjunto se nombra con una letra mayúscula $S$ o también con **$\Omega$**
</div>

+ $S_{1}$= $\{ (cc), (cs), (sc), (ss) \}$  

<br/>

:::: {style="display: flex;"}

::: {}

+ $\begin{equation*}
	S_{2}=\left\{
	\begin{array}{cccccc}
		&(1,1),(1,2),(1,3),(1,4),(1,5),(1,6)&\\
		&(2,1),(2,2),(2,3),(2,4),(2,5),(2,6)&\\
		&(3,1),(3,2),(3,3),(3,4),(3,5),(3,6)&\\
		&(4,1),(4,2),(4,3),(4,4),(4,5),(4,6)&\\
		&(5,1),(5,2),(5,3),(5,4),(5,5),(5,6)&\\
		&(6,1),(6,2),(6,3),(6,4),(6,5),(6,6)&
	\end{array}
	\right\}
\end{equation*}$ 

:::

::: {}

```{r, echo=FALSE, out.width="150%", fig.align = "center"}
knitr::include_graphics("img/dados.png")
```
:::

::::

<br/><br/>

+ $S_{3}$= $\{ x \in \mathbb{R} | 0 \leq x \leq 5   \}$ 

<br/>

+ $S_{4}$= $\{ x \in \mathbb{N}| 0 \leq x \leq 1 \}$ 

<br/>

+ $S_{5}$= $\{ x \in \mathbb{N}| 0 \leq x \leq 20 \}$

<br/><br/>

Algunos de los conjuntos se definen por extensión  ($S_{1}$, $S_{2}$ )y otros por compresión ($S_{3}$, $S_{4}$ y $S_{5}$)

<br/><br/><br/>

## <span style="color:#034a94">**Evento aleatorio**</span>

<br/>
<div class="content-box-blue">
Subconjunto del espacio muestral que es de nuestro interés. Como todo conjunto, se nombra con una letra mayúscula por lo general las primeras letras del alfabeto
</div>


|           |                                       |                      |
|:----------|:--------------------------------------|:---------------------|
|$A_{1}$    | Obtener solo caras                    | $A_{1}=\{ (c,c)\}$
| $A_{2}$   | Sacar un resultados es inferior a 4   | $A_{2}=\{(1,1),(1,2)(2,1)\}$
| $A_{3}$   | Ganar el examen                       | $A_{3}=\{ x \in \mathbb{R} | 3.0 \leq x \leq 5.0 \}$
| $A_{4}$   | Cumplir el objetivo de la salida      | $A_{4} =\{ 1 \}$
| $A_{5}$   | Obtener más de 5 ensayos exitosos     | $A_{5}$= $\{ x \in \mathbb{N}| 6 \leq x \leq 20 \}$

<br/><br/>


<br/><br/><br/>

## <span style="color:#034a94">**Enfoques de probabilidad**</span>

<br/><br/><br/>

### <span style="color:#034a94">**Enfoque clásico**</span>  

<br/>

Es el enfoque más antiguo de probabilidad y que está basado en el supuesto de eventos individuales igualmente probables. La probabilidad bajo este enfoque para el evento $A$ se calcula como la fracción entre el número de elementos del conjunto $A$, $n(A)$ y el número de elementos del espacio muestral $n(S)$: 


<div class="content-box-blue">
$$P(A)=\dfrac{n(A)}{n(S)}$$
</div>

<br/><br/>

### <span style="color:#FF7F00"> **Ejemplo**</span> 

* Probabilidad de sacar un doble seis al lanzar dos dados
* Probabilidad de elegir un `As` en una baraja de cartas

<br/><br/><br/>

### <span style="color:#034a94">**Enfoque Frecuentista**</span>

<br/>

Este enfoque basa su cálculo en la frecuencia con que ocurre un evento en un tamaño de muestra determinado $n$.

<div class="content-box-blue">
$$\lim_{n \to{+}\infty} P(A)=\Bigg[ \dfrac{\text{número de veces que ocurre A}}{n} \Bigg]$$
</div>

<br/><br/>

### <span style="color:#FF7F00"> **Ejemplo**</span> 

* Probabilidad de ganar un examen
* Probabilidad de realizar más de 10 ventas en un dia
<br/><br/><br/>

### <span style="color:#034a94">**Enfoque subjetivo**</span> 

<br/>

En este caso la probabilidad es valorada y asignada por un **EXPERTO**, como un médico, un ingeniero, un abogado, un economista, un biólogo, un estadístico, un mecánico ......

<div class="content-box-blue">
$$P(A)   \gets \text{Experto}$$  
</div>

<br/><br/>

### <span style="color:#FF7F00"> **Ejemplo**</span> 

* Probabilidad de tener éxito en una operación de pterigio
* Probabilidad de que se rompa la cadena del distribución de un auto

<br/><br/><br/>

## <span style="color:#034a94">**Axiomas de probabilidad**</span>

Los siuientes cinco axiomas corresponde a las condiciones mínimas que se deben verificar sobre los elemtos basícos ($E$, $S$, $A$). Fueron formuladas por Andréi Kolmogórov (1933) 


<div class="content-box-blue">

+ $A_{1}$ : Sea $S$ un espacio muestral  asociado a un experimento. Entonces:

$$P(S)=1$$ 

+ $A_{2}$ : Para cualquier evento $A$, se cumple que:

$$0 \leq P(A) \leq 1$$ 

+ $A_{3}$ : Si $A$ y $B$ son dos eventos mutuamente excluyentes, entonces: 
$$P(A \cup B) = P(A) + P(B)$$ 
En general 

$$P(A \cup B) = P(A)+ P(B) - P(A \cap B)$$ 


+ $A_{4}$ : Para cualquier evento $A$, $P(A')=1-P(A)$

+ $A_{5}$ : La probabilidad que no ocurra nada : 

$$P(\phi) = 0$$   

</div>

